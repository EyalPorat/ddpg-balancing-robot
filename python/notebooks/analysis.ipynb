{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Balancing Robot Analysis\n",
                "\n",
                "This notebook provides comprehensive analysis of the trained models and robot behavior."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "\n",
                "from src.balancing_robot.models import Actor, Critic, SimNet\n",
                "from src.balancing_robot.environment import BalancerEnv, SimNetBalancerEnv\n",
                "from src.balancing_robot.visualization import (\n",
                "    plot_training_metrics,\n",
                "    create_episode_animation,\n",
                "    plot_predictions_comparison,\n",
                "    plot_state_distributions\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load DDPG model\n",
                "env = BalancerEnv()\n",
                "state_dim = env.observation_space.shape[0]\n",
                "action_dim = env.action_space.shape[0]\n",
                "max_action = float(env.action_space.high[0])\n",
                "\n",
                "actor = Actor(state_dim, action_dim, max_action)\n",
                "actor.load_state_dict(torch.load('logs/ddpg_training/best_actor.pt')['state_dict'])\n",
                "\n",
                "# Load SimNet model\n",
                "simnet_checkpoint = torch.load('logs/simnet_training/simnet_final.pt')\n",
                "simnet = SimNet(\n",
                "    state_dim=simnet_checkpoint['metadata']['state_dim'],\n",
                "    action_dim=simnet_checkpoint['metadata']['action_dim'],\n",
                "    hidden_dims=simnet_checkpoint['metadata']['hidden_dims']\n",
                ")\n",
                "simnet.load_state_dict(simnet_checkpoint['state_dict'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Compare Different Simulation Methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_episode(env, actor, max_steps=500):\n",
                "    \"\"\"Run single episode and collect data.\"\"\"\n",
                "    state = env.reset()\n",
                "    states, actions, rewards = [], [], []\n",
                "    \n",
                "    for _ in range(max_steps):\n",
                "        action = actor.select_action(state)\n",
                "        next_state, reward, done, info = env.step(action)\n",
                "        \n",
                "        states.append(state)\n",
                "        actions.append(action)\n",
                "        rewards.append(reward)\n",
                "        \n",
                "        if done:\n",
                "            break\n",
                "            \n",
                "        state = next_state\n",
                "    \n",
                "    return np.array(states), np.array(actions), np.array(rewards), info\n",
                "\n",
                "# Create environments\n",
                "physics_env = BalancerEnv()\n",
                "simnet_env = SimNetBalancerEnv(simnet=simnet, hybrid_ratio=1.0)\n",
                "hybrid_env = SimNetBalancerEnv(simnet=simnet, hybrid_ratio=0.5)\n",
                "\n",
                "# Run episodes\n",
                "num_episodes = 100\n",
                "results = {\n",
                "    'physics': {'rewards': [], 'lengths': [], 'states': []},\n",
                "    'simnet': {'rewards': [], 'lengths': [], 'states': []},\n",
                "    'hybrid': {'rewards': [], 'lengths': [], 'states': []}\n",
                "}\n",
                "\n",
                "for env_name, env in [\n",
                "    ('physics', physics_env),\n",
                "    ('simnet', simnet_env),\n",
                "    ('hybrid', hybrid_env)\n",
                "]:\n",
                "    for _ in tqdm(range(num_episodes), desc=f\"Running {env_name}\"):\n",
                "        states, actions, rewards, info = run_episode(env, actor)\n",
                "        results[env_name]['rewards'].append(sum(rewards))\n",
                "        results[env_name]['lengths'].append(len(rewards))\n",
                "        results[env_name]['states'].append(states)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Performance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot reward distributions\n",
                "plt.figure(figsize=(10, 6))\n",
                "for env_name in results:\n",
                "    sns.kdeplot(results[env_name]['rewards'], label=env_name)\n",
                "plt.title('Reward Distributions')\n",
                "plt.xlabel('Total Episode Reward')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()\n",
                "\n",
                "# Plot episode length distributions\n",
                "plt.figure(figsize=(10, 6))\n",
                "for env_name in results:\n",
                "    sns.kdeplot(results[env_name]['lengths'], label=env_name)\n",
                "plt.title('Episode Length Distributions')\n",
                "plt.xlabel('Steps')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## State Space Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot state distributions for each environment\n",
                "for env_name in results:\n",
                "    states = np.concatenate(results[env_name]['states'])\n",
                "    fig = plot_state_distributions(\n",
                "        states,\n",
                "        save_path=f'logs/analysis/{env_name}_state_dist.png'\n",
                "    )\n",
                "    plt.suptitle(f'State Distributions - {env_name}')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Stability Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_stability(states):\n",
                "    \"\"\"Compute stability metrics for episode.\"\"\"\n",
                "    return {\n",
                "        'max_angle': np.max(np.abs(states[:, 0])),\n",
                "        'avg_angle': np.mean(np.abs(states[:, 0])),\n",
                "        'max_pos': np.max(np.abs(states[:, 2])),\n",
                "        'avg_pos': np.mean(np.abs(states[:, 2])),\n",
                "        'angular_velocity_std': np.std(states[:, 1]),\n",
                "        'position_velocity_std': np.std(states[:, 3])\n",
                "    }\n",
                "\n",
                "stability_metrics = {env_name: [] for env_name in results}\n",
                "\n",
                "for env_name in results:\n",
                "    for episode_states in results[env_name]['states']:\n",
                "        metrics = analyze_stability(episode_states)\n",
                "        stability_metrics[env_name].append(metrics)\n",
                "\n",
                "# Plot stability metrics\n",
                "metric_names = list(stability_metrics['physics'][0].keys())\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "\n",
                "for ax, metric in zip(axes.flat, metric_names):\n",
                "    for env_name in results:\n",
                "        values = [m[metric] for m in stability_metrics[env_name]]\n",
                "        sns.kdeplot(values, label=env_name, ax=ax)\n",
                "    ax.set_title(metric)\n",
                "    ax.grid(True)\n",
                "    ax.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Energy Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_energy_metrics(states, actions):\n",
                "    \"\"\"Compute energy-related metrics.\"\"\"\n",
                "    kinetic_energy = 0.5 * (states[:, 1]**2 + states[:, 3]**2)\n",
                "    potential_energy = 9.81 * (1 - np.cos(states[:, 0])) * 0.025  # mgl(1-cos(theta))\n",
                "    control_effort = np.sum(actions**2)\n",
                "    \n",
                "    return {\n",
                "        'avg_kinetic': np.mean(kinetic_energy),\n",
                "        'max_kinetic': np.max(kinetic_energy),\n",
                "        'avg_potential': np.mean(potential_energy),\n",
                "        'max_potential': np.max(potential_energy),\n",
                "        'total_control_effort': control_effort\n",
                "    }\n",
                "\n",
                "energy_metrics = {env_name: [] for env_name in results}\n",
                "\n",
                "for env_name in results:\n",
                "    for states, actions in zip(results[env_name]['states'],\n",
                "                              results[env_name]['actions']):\n",
                "        metrics = compute_energy_metrics(states, actions)\n",
                "        energy_metrics[env_name].append(metrics)\n",
                "\n",
                "# Plot energy metrics\n",
                "metric_names = list(energy_metrics['physics'][0].keys())\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "\n",
                "for ax, metric in zip(axes.flat, metric_names):\n",
                "    for env_name in results:\n",
                "        values = [m[metric] for m in energy_metrics[env_name]]\n",
                "        sns.kdeplot(values, label=env_name, ax=ax)\n",
                "    ax.set_title(metric)\n",
                "    ax.grid(True)\n",
                "    ax.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Statistical Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy import stats\n",
                "\n",
                "def perform_statistical_analysis(results):\n",
                "    \"\"\"Perform statistical tests comparing different environments.\"\"\"\n",
                "    metrics = ['rewards', 'lengths']\n",
                "    pairs = [('physics', 'simnet'), \n",
                "             ('physics', 'hybrid'), \n",
                "             ('simnet', 'hybrid')]\n",
                "    \n",
                "    analysis_results = {}\n",
                "    \n",
                "    for metric in metrics:\n",
                "        analysis_results[metric] = {}\n",
                "        \n",
                "        for env1, env2 in pairs:\n",
                "            # T-test\n",
                "            t_stat, p_val = stats.ttest_ind(\n",
                "                results[env1][metric],\n",
                "                results[env2][metric]\n",
                "            )\n",
                "            \n",
                "            # Effect size (Cohen's d)\n",
                "            d = (np.mean(results[env1][metric]) - np.mean(results[env2][metric])) / \\\n",
                "                np.sqrt((np.var(results[env1][metric]) + np.var(results[env2][metric])) / 2)\n",
                "            \n",
                "            analysis_results[metric][f'{env1}_vs_{env2}'] = {\n",
                "                't_statistic': t_stat,\n",
                "                'p_value': p_val,\n",
                "                'cohens_d': d\n",
                "            }\n",
                "    \n",
                "    return analysis_results\n",
                "\n",
                "# Perform analysis\n",
                "stats_results = perform_statistical_analysis(results)\n",
                "\n",
                "# Print results in a formatted table\n",
                "for metric in stats_results:\n",
                "    print(f\"\\n=== {metric.upper()} ===\")\n",
                "    print(f\"{'Comparison':<20} {'t-stat':>10} {'p-value':>10} {'Cohen\\'s d':>10}\")\n",
                "    print(\"-\" * 50)\n",
                "    \n",
                "    for comparison, stats_dict in stats_results[metric].items():\n",
                "        print(f\"{comparison:<20} {stats_dict['t_statistic']:10.3f} \"\n",
                "              f\"{stats_dict['p_value']:10.3f} {stats_dict['cohens_d']:10.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## SimNet Prediction Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_prediction_accuracy(simnet_env, num_steps=1000):\n",
                "    \"\"\"Analyze accuracy of SimNet predictions compared to physics.\"\"\"\n",
                "    predictions = {'physics': [], 'simnet': []}\n",
                "    states = []\n",
                "    actions = []\n",
                "    \n",
                "    state = simnet_env.reset()\n",
                "    for _ in range(num_steps):\n",
                "        action = actor.select_action(state)\n",
                "        \n",
                "        # Get predictions from both models\n",
                "        physics_pred = simnet_env.physics.get_acceleration(state, action)\n",
                "        simnet_pred = simnet_env.simnet.get_accelerations(state, action)\n",
                "        \n",
                "        predictions['physics'].append(physics_pred)\n",
                "        predictions['simnet'].append(simnet_pred)\n",
                "        states.append(state)\n",
                "        actions.append(action)\n",
                "        \n",
                "        # Step environment\n",
                "        state, _, done, _ = simnet_env.step(action)\n",
                "        if done:\n",
                "            state = simnet_env.reset()\n",
                "    \n",
                "    return np.array(states), np.array(actions), predictions\n",
                "\n",
                "# Analyze predictions\n",
                "states, actions, predictions = analyze_prediction_accuracy(simnet_env)\n",
                "\n",
                "# Plot prediction differences\n",
                "component_names = ['θ̈ (rad/s²)', 'ẍ (m/s²)', 'φ̈ (rad/s²)']\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "for i, (ax, name) in enumerate(zip(axes, component_names)):\n",
                "    physics = [p[i] for p in predictions['physics']]\n",
                "    simnet = [p[i] for p in predictions['simnet']]\n",
                "    \n",
                "    ax.scatter(physics, simnet, alpha=0.5, s=1)\n",
                "    ax.plot([-1, 1], [-1, 1], 'r--', alpha=0.8)\n",
                "    ax.set_xlabel('Physics Prediction')\n",
                "    ax.set_ylabel('SimNet Prediction')\n",
                "    ax.set_title(name)\n",
                "    ax.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Calculate error metrics\n",
                "errors = np.array(predictions['physics']) - np.array(predictions['simnet'])\n",
                "error_metrics = {\n",
                "    'MSE': np.mean(errors**2, axis=0),\n",
                "    'MAE': np.mean(np.abs(errors), axis=0),\n",
                "    'Max Error': np.max(np.abs(errors), axis=0)\n",
                "}\n",
                "\n",
                "print(\"\\nError Metrics:\")\n",
                "print(f\"{'Metric':<10} {'θ̈':>10} {'ẍ':>10} {'φ̈':>10}\")\n",
                "print(\"-\" * 40)\n",
                "for metric, values in error_metrics.items():\n",
                "    print(f\"{metric:<10} {values[0]:10.3f} {values[1]:10.3f} {values[2]:10.3f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}